# SQLにおける実行モデル

## この文書について

この文書では、SQLを実行する実行エンジンの、抽象的な実行モデルを規定し、検証するための土台とする。
また、実行モデル上での実行内容を表現する物理実行計画に求められる要件についても併せて検討する。

なお、本方針は「 [SQLにおける副問合せの展開方法](subquery-expansion.md) 」の内容を前提にしている。

## コンセプトデザイン

### モデル

本実行モデルでは、SQLの実行内容を3種類の層に分類する。

1. スカラー演算木
   * スカラー演算を表現する演算木
   * 下記の「関係演算グラフ」中に出現する
2. 関係演算グラフ
   * 関係演算子をもとにした物理演算子からなる有向グラフ
   * 別紙「SQLにおける副問合せの展開方法」にある「正規形」を前提とする
3. ステップグラフ
   * 処理単位である「ステップ」を頂点にとり、ステップ間の依存関係を辺として表す非循環の有向グラフ (DAG)
   * ステップは以下の2種類からなる
     1. プロセス - 関係演算グラフから「ほかの処理の待ち合わせなく行える」ような部分グラフを抽出し、その部分グラフを内包するようなステップ
     2. エクスチェンジ - プロセス間でデータ交換を行うステップ
        * プロセスでは行えなかった「待ち合わせ」を要する処理（ソートなど）を内包することができる
        * プロセス同士は直接のデータ交換を行わず、必ずエクスチェンジを介してやり取りする

### 期待する特性

本モデルの採用にあたり、以下の効果を期待する。

* 各関係演算子の個別の処理と、プログラム全体のスケジューリングの問題を分離する
  * 関係演算子の処理はSQLドメイン特有の問題であり、それらの問題をステップグラフのステップの内部に凝集させたい
  * 対して、それらをどのような順番で、どのように実行するかはSQLドメインから独立しており、ステップグラフ全体として取り扱う
* 並列化やリソース割り当てを容易に実現する
  * 並列化やリソース割り当ては本質的にスケジューリングの問題であり、SQLとは独立して設計可能
  * ステップグラフの概念を導入することで、「各ステップをどのように並列化するか」「ステップをどの順番で実行するか」という問題に帰着できる
* コード生成方式を段階的に実現する
  * ステップグラフ上のスケジューリング、プロセス内部の関係演算グラフの実行、エクスチェンジ処理の実行はそれぞれ独立しており、必要な時期に独立してコード生成方式を投入することができる
  * または、関係演算と、スカラー演算を構造的に分離することで、部分的なコード生成化が望める

## ステップグラフ

ステップグラフは、プロセスとエクスチェンジが交互にステップとして出現し、それらの間を有向辺で接続した非循環の有向グラフである。

プロセスを実行することでエクスチェンジに出力データを蓄積し、必要なすべてのエクスチェンジがデータの蓄積・加工を完了したら、後続のプロセスがそれらを入力として自身の処理を実行する。これらを繰り返すことでステップグラフ全体の処理を進めていくことになる。

ステップグラフ上の各ステップ、つまりプロセスやエクスチェンジは、元の関係演算グラフを演算子の特性ごとに分類した上で、部分グラフを割り当てられる。

プロセスはその特性上、関係演算グラフのうち「待ち合わせ」を含まない部分の処理を担当する。このとき、その部分を大きくとることでデータ交換に係るオーバーヘッドを削減できる。

対して、エクスチェンジはプロセスに含められなかった「待ち合わせ」を要する部分の処理を担当する。例えば、グループ化やソートなどがこれに該当する。エクスチェンジ上でこれらの処理を行ったうえで、グループ化の単位や、またはリレーション全体を後段のプロセスの入力とすることで、結合や集計などの複雑な処理を、自身が内部で待ち合わせを行うことなく実現できる。

このように、待ち合わせの有無や実行順序をステップグラフで管理することで、ステップグラフを実行するエンジンは処理全体を見渡しながら適切なリソース配分を行うことができる。また、プロセスの内部を実行するエンジンを分離して開発することもできる。

### ステップグラフの用語

入力エクスチェンジ
~ あるプロセスに対して、プロセスにデータを供給するエクスチェンジ

出力エクスチェンジ
~ あるプロセスに対して、プロセスが出力したデータを交換するエクスチェンジ

上流
~ あるステップに対し、そのステップに入力データを直接供給するステップ

下流
~ あるステップに対し、そのステップが出力データを直接供給するステップ

可達
~ あるステップに対し、対象のステップが上流または再帰的に上流のステップであることを「上流可達」とよび、下流も同様に「下流可達」とよぶ

  上流可達または下流可達であることを単に「可達」とよぶ

併流
~ あるステップ `u` に対し、対象のステップ `v` が以下のすべてを満たすこと

  * `u` と `v` は同一のステップではない
  * `u` に対して、 `v` は可達でない

### ステップグラフの特性

* ステップグラフ上のすべてのステップ（プロセス、エクスチェンジ）を実行することで、元となったSQLを実行したことになる
  * プロセスを実行するとエクスチェンジにデータを提供し、エクスチェンジが加工して次のプロセスにデータを供給する、という連続によって実行を制御する
  * おおよそ、プロセスを関係演算子を合成したもの、エクスチェンジをその結果のリレーションとみなすこともできる
    * ただし、エクスチェンジ自体も一定の演算（ソートなど）を行うので、物理実行計画において上記は厳密には異なる
* あるプロセスを「実行」するとは、プロセスの入力エクスチェンジからデータを取得し、プロセスの定義に従ってデータを変形したのち、出力エクスチェンジに結果を蓄積することである
* あるプロセスが「完了」したとは、そのプロセスを実行した結果、必要なすべての出力を出力エクスチェンジに提供し終わった状態を表す
* あるエクスチェンジを「実行」するとは、エクスチェンジに蓄積されたデータを、エクスチェンジの定義に従って変換することである
* あるエクスチェンジが「完了」したとは、上流のプロセスから必要なすべてのデータを受け取り、データ全体を下流のプロセスに対して提供可能になった状態を表す
* 原理モデルにおいて、ステップを「実行」するためには、その上流のすべてのステップが「完了」した状態でなければならない
  * ただし、特定条件下において、完了していなくても部分を「実行」することは可能である

### エクスチェンジの特性

* エクスチェンジとプロセスの対応関係は以下の通り
  * エクスチェンジは、複数のプロセスからの出力を受け取れる
    * エクスチェンジの上流が複数のプロセスである場合、暗黙にそれらの出力の連接 (`union all`) に対して処理を行う
      * これは重要な特性で、ステップグラフ構成時の自由度を担保するために必要
      * `union all` 以外の `union` を行う場合、下記の `shuffle` を利用する
  * エクスチェンジは、複数のプロセスの入力として取り扱える
    * この場合のセマンティクスは、エクスチェンジに登録されたデータをそれぞれ **複製して** プロセスの入力に引き渡す
  * プロセスが何らかの入力リレーションを受け取る場合、それに対応する入力エクスチェンジは必ず単一である
  * プロセスが何らかの出力を行う際、対応する出力エクスチェンジは複数個あってもよい
* エクスチェンジは大別すると4種類の処理（エクスチェンジ種）に分けられる
  1. `forward`
     * 上流のプロセスから受け取ったデータ片を、その単位（または、「行」の単位に細分化）で下流のプロセスに供給する
       * 原理的には、すべてのプロセスは単一の関係演算子のみを含み、演算子間で待ち合わせが不要なものは `forward` で接続することでも、同等の結果を得られるステップグラフになる
       * 全体の行数の最大値を定められる
     * 主に以下の関係演算子の一部または全部に対応する
       * `union{all}` - リレーションの連接
       * `limit` - リレーション全体での行数制限
         * プロセス内で行ってもよいのだが、プロセスをステートレスにすることで並列化が望める
     * プロセスを強制的に分割する際にも利用する。

       たとえば、自己結合を map based join で行うケースについて考えると、同処理は疑似的に `join(U, broadcast(U))` のように表せる。

       このとき、map based join 自体は待ち合わせを要しないため素直にプロセスを構成しようとすると、そのプロセスは `broadcast(U)` を出力しつつ、さらにそれを入力としようとするため、循環が発生してしまう。

       上記を回避するには `join(forward(U), broadcast(U))` のように、一見意味のない `forward` を介すことでプロセスを分割する必要がある。
  2. `shuffle`
     * 上流のプロセスから受け取ったデータ片をかき集め、指定されたキーでグループ化したうえで下流のプロセスにグループ単位で供給する
       * リレーション全体で一つのグループとしてもよい
       * それぞれのグループ分けは、直和分割でなければならない
         * つまり、同一のグループのデータが別のグループであるかのように供給されてはならない
       * 各グループ内の行はソートできる
       * 各グループ内の行数の最大値を定められる
     * 主に以下の関係演算子の一部または全部に対応する
       * `join` - sort merge join の際に、sort までを行う
       * `aggregate` - `GROUP BY` 相当
       * `distinct` - 同値類ごとの行数を高々1行に制限
       * `limit` - グループ化した状態での `limit` や, `TOP N` 相当
       * `sort` - グループを分割しないことで、リレーション全体をグループとして後段の入力にとれる
  3. `broadcast`
     * 上流のプロセスから受け取ったデータ辺をかき集め、全体を下流のプロセスに供給する
     * 主に以下の関係演算子の一部または全部に対応する
       * `join` - map join を行う際の map 側を構成する
  4. `discard`
     * データの交換を行わない (単にプロセスのブロッカーとして働く)
     * 対応する関係演算子は存在しない
* エクスチェンジが `union{all}` 相当の挙動をする関係上、リレーション内で行IDが重複してしまう可能性がある
  * このため、下流の処理で行IDが要求される場合、重複しうるならば再度の割り当てが必要になる

### プロセスの特性

* プロセスが入力にとれるエクスチェンジには以下のような制約がある
  * プロセスが `forward` を入力エクスチェンジに持つ場合、ほかの入力エクスチェンジは `broadcast`, `discard` のいずれかでなければならない
  * プロセスが `shuffle` を入力に持つ場合、ほかの入力エクスチェンジは `broadcast`, `discard`, または同じキーでグループ化された `shuffle` でなければならない
* 上記の制約により、 `forward` または `shuffle` の組を「主入力エクスチェンジ」とよぶ
  * 対して、 `broadcast`, `discard` を「副入力エクスチェンジ」とよぶ
* 主入力エクスチェンジが2個以上の `shuffle` である場合、sorted merge を企図したものである
  * そのため、 `shuffle` 入力 `A`, `B` があるとき、 `A` と `B` に含まれる同一のグループを簡単に取り出せる必要がある
  * これを実現するには、キーでグループ化したうえで、各グループをキーの順序に並び替えるなどがある

### 並行実行モデル

* 併流の関係にある複数のプロセスは、並行して実行可能である
* あらゆるエクスチェンジは、並行して実行可能である
* 主入力エクスチェンジが供給するデータを水平分割することで、ほとんどのプロセスは並列実行できる
  * ただし、主入力エクスチェンジからの入力単位に対し、プロセスそのものが自明な並列性を有する必要がある
  * 複数入力の `shuffle` を含むプロセスを実行するには、入力エクスチェンジ間で同じグループは水平分割時に同じ分割に含められなければならない
  * 副入力エクスチェンジからのデータは分割しない
* 主入力エクスチェンジが一つも存在しないプロセスは、基本的にスキャン (`scan`) 演算子を含んでいる
  * この場合、スキャン範囲を分割することで、主入力エクスチェンジが存在する場合と同等の並列化が望める
* プロセスを並列実行する場合、それらの出力エクスチェンジはデータの蓄積に何らかの同期処理が必要になる場合がある
  * スレッドごとに異なるエクスチェンジのストレージを持つ、などの方法が考えられるが、本文書では規定しない
* 以下のエクスチェンジは並列実行可能である
  * `forward`
    * 自明な並列性がある
  * `shuffle`
    * グループ化を行う際に、グループを少数の「パーティション」に分類することで、パーティションごとに並列処理が可能
  * `broadcast`
    * map join を行う場合などに、並列アルゴリズムを選択することで並列処理が可能 (sorted arrayを利用したjoinなど)

なお本文書では、各プロセスが自明な並列性を有するものとして以降の設計を行う。

### ステップグラフの最適化

#### エクスチェンジのインクリメンタル処理

エクスチェンジは、原理モデルにおいては上流のステップが完了するまで、その処理を実行することはできない。

しかしながら、いくつかの処理は上流からデータが供給されるたびにインクリメンタルに処理を行っても、最終的に得られる結果が変わらない。
以下はその例である。

* `shuffle`
  * `aggregate`
    * 同値類にグループ化する際に、インクリメンタルに集約できる
  * `distinct`
    * 同値類にグループ化する際に、インクリメンタルに重複を除去できる
  * `limit`
    * 同値類にグループ化する際に、インクリメンタルに個数を制限できる
* `broadcast`
  * `join`
    * ハッシュ表をインクリメンタルに構築できる

上記を実行するには、エクスチェンジにアプリケーション固有の処理をプッシュダウンすることが必要になり、実装が煩雑になる可能性がある。

一方で、上記を実現することでエクスチェンジに蓄積されるデータ量そのものを削減できる。
特に、テーブル全体を集約するような計算においては、 `aggregate` の処理をエクスチェンジ内でインクリメンタルに実施することで、蓄積すべき行を高々1行に削減できる。

#### `forward` の早期フェッチ

`forward` を主入力エクスチェンジとするプロセスは、当該 `forward` が完了していなくても部分的にその処理を実行できる。

* `forward` はそれ自身が待ち合わせを行わないため、上流から出力されたデータを即座に下流で利用可能
* これをうまく用いることで、並列度を調整できる。 `step1 -> forward -> step2` としたときに:
  * 入力が特定のスレッドのみから行える場合、 `step1` をそのスレッド上で実行し、 `step2` は任意のワーカースレッドで並列実行できる
  * 出力が特定のスレッドのみから行える場合、 `step2` をそのスレッド上で実行し、 `step1` は任意のワーカースレッドで並列実行できる
* ただし、同プロセスを完了させるには、 `forward` もまた完了していなければならない

#### `broadcast` の早期フェッチ

`broadcast` は副入力エクスチェンジであり、主入力エクスチェンジのような水平分割は行えない。
代わりに、主入力を水平分割して処理した際に、同一の `broadcast` からは常に同じ内容のデータが供給されることになる。

これはつまり、副入力エクスチェンジの内容を加工してプロセス内で使用する場合に、分割された主入力エクスチェンジの内容に因らずに加工を行える。
このため、主入力エクスチェンジが実行可能になる前に、対象の `broadcast` が一部または全部のデータがそろっている場合、その `broadcast` を加工するような初期化処理の一部または全部を先行して行える。

ただし、これは「エクスチェンジのインクリメンタル処理」と一部の内容が重複する可能性がある。
`broadcast` の早期フェッチを採用する場合の利害得失について以下に示す。
なお、初期化内容は「結合用の表を作成する」と仮定する。

* Pros.
  * 当該 `broadcast` の結果を利用する下流のプロセスが複数存在し、かつそれぞれで表のキーが異なる場合に、必要に応じて表を作成し、不要になればその表を破棄することができるため、メモリー使用量を削減できる
    * インクリメンタル方式では、それぞれのキーに対して別個の表を作成しなければならない
  * 当該 `broadcast` にデータの一部が蓄積された時点で、下流のプロセスがそれを消費して結合表を漸近的に構築することで、 `broadcast` 自体に蓄積されるデータを削減できる
    * これは前述の「 `forward` の早期フェッチ」と類似の動作である
* Cons.
  * 当該 `broadcast` の結果を利用する下流のプロセスが複数存在しない場合、エクスチェンジは原票を保持し、さらにプロセスで結合用の表を構築するため、一時的に二重のメモリー容量が必要になる
  * エクスチェンジの外で結合用の表を構築するため、同表を並列に構築する場合、プロセスの初期化処理についても並列化の仕組みを導入する必要がある
  * 漸近的に結合表を構築する場合、実行エンジンの構造がやや複雑になる

なお、現在は `broadcast` エクスチェンジが取り扱うデータ量について特に想定はしていない。
取り扱うデータ量が十分に小さな場合、本最適化はあまり効果をなさないと考える。

#### `forward` による並列化のリバランス

プロセスとプロセスの間に `forward` エクスチェンジを挿入することで、前後のプロセスの並列度をスケジューラが外側から自由に調整することができる。

例えば、 `shuffle` にプロセスが後続し、かつ `shuffle` のグループ化に大きな偏りが予想される上に、プロセス自体の内容が複雑である場合には、プロセスを分割して `forward` 以降に複雑な処理を配置してやれば、データの偏りを平準化して複雑な処理を実行できる。

ただし、 `forward` エクスチェンジ自体の実行にも一定のコストを要するため、適切に行う必要がある。

## プロセス

プロセスは、関係演算グラフのうち、待ち合わせが不要な部分の部分グラフからなる。

### プロセスの基本的なデザイン

前項での「並列実行モデル」を念頭に置いてデザインすると、次のようなモデルが適当であろうと考える。

* プロセスは並列化のために、複数回に分けて実行することになる
  * プロセスの一回分の処理を「スライス」とよぶ
  * プロセスを実行するとは、プロセスのすべてのスライスを実行することに等しい
* 各関係演算子は、行またはグループを入力にとり、それらを処理して後続の演算子に引き渡す「プロシージャ」であると考える
  * プロシージャが次のプロシージャを連鎖的に呼び出す構造であるため、プロセス全体の処理は単一のプロシージャで表現できる
  * スライスの最小単位の処理内容は、上記の入力1回分に対し、上記のプロシージャを呼び出すことに等しい

以降の解説では、スライスは上記の最小単位の処理を担う前提で議論する。

### 特殊な演算子

本モデルにおけるプロセス内で関係演算を実現するにあたって、通常の関係演算子とは別に、必要と考えられる特殊な演算子を挙げる。

`take`
~ 主入力エクスチェンジから次の処理単位データを一つ取り出す。

  主入力エクスチェンジが `forward` である場合、本演算子は次の1行を取り出す。

  主入力エクスチェンジが `shuffle` である場合、本演算子は当該プロセスのすべての主入力エクスチェンジ (制約上、いずれも `shuffle`) について、それぞれの入力エクスチェンジに共有の次の1グループを取り出す。このとき、当該グループがいくつかの入力エクスチェンジに存在しない場合、それらは「空のグループ」として取得する。

  副入力エクスチェンジについては、のちに議論する。

`offer`
~ 出力エクスチェンジに処理結果を提供する

`emit`, `write`
~ DML関連の疑似演算子

`buffer`
~ ある演算子の出力結果を2個以上の演算子が利用する際に、それぞれの演算子に結果を配布するような演算子。

  この演算子を導入することで、「 `buffer` を除くすべての演算子の出力は、高々1つの演算子しか利用しない」という制約を導入できる。

  この演算子が必要になるのは、後続の演算子に対応するプロシージャが何らかの副作用を持つ場合である。
  そのような場合、必要な環境を退避したのちに対象のプロシージャを実行し、退避した環境を復元したのちに次のプロシージャを実行することで、副作用の影響を回避する。

### プロセス演算グラフの構造

各々のプロセスに内包する関係演算グラフの部分グラフ（以下、プロセス演算グラフ）は、以下のような特性を持つ。

* プロセス演算グラフは非循環である (非循環の関係演算グラフの部分グラフ)
* プロセスの先頭の演算子は、 `scan`, `take` のいずれかである
  * これらの演算子を「ソース演算子」とよぶ
  * ソース演算子は、各プロセスにちょうど1つだけ存在する
    * `shuffle` エクスチェンジが複数あっても、 `take` はそれらを束ねて1つだけ存在することになる
  * ソース演算子は、0入力、1出力である
  * なお、 `scan` は便宜上のもので、物理演算子はいくつかのバリエーションが存在しうる
* プロセスの末尾の演算子は、 `offer`, `emit`, `write` のいずれかである
  * これらの演算子を「シンク演算子」とよぶ
  * ソース演算子と異なり、シンク演算子は複数存在してもよい（ただし、1つ以上必要）
  * シンク演算子は、1入力、0出力である
* プロセスの先頭でも末尾でもない演算子は、「リレー演算子」とよぶ
  * ソース、シンク、リレー演算子はいずれも重複しない
  * リレー演算子は、 `buffer` を除き 1入力、1出力である
    * `buffer` は2出力以上
    * なお、 `join` や `union` などは、本来2つのリレーションを入力にとるが、プロセス演算グラフ上のモデルでは、「2つのグループの組」という1つの入力とみなしている
    * 上記の入力とは別に、演算子は `broadcast` から得られるデータを取り扱ってよい
* `broadcast` エクスチェンジからの入力データは、すべての演算子がデータを取得可能
  * `broadcast` に対応する演算子は導入せず、 `broadcast` によって提供されるデータをプロシージャから取得するためのAPIを提供する
    * `broadcast` のデータは同一プロセスのすべてのスライスで共通であり、各スライスの実行前にプロセス全体の初期化ルーチンを実行し、そこで `broadcast` を初期化する方式がよいか
* 上記のプロセスを、以下のいずれかまで繰り返す
  * ソース演算子がすべての入力の範囲のデータを取り出した
  * シンク演算子がこれ以上の処理を不要だと判断した (出力エクスチェンジが `limit` を処理している場合など)
  * その他、何らかのエラーが発生した

上記の原理モデルでは、プロセス演算グラフは常にソース演算子を根、リレー演算子を枝、シンク演算子を葉とするツリー構造になる。

### プロセスの実現例

以下、プロセスの疑似コードを示す。

```python
# offer(project{x=x+1}(filter{x<10}(take())))
def execute_slice():
  procedure_take()

def procedure_take():
  record = take_next_record()
  procedure_filter(record)

def procedure_filter(record):
  if record.x < 10:
    procedure_project(record)

def procedure_project(record):
  record.x = record.x + 1
  offer(record)
```

```python
# emit(join{left-outer}{L.x=R.x}(take())) -- by shuffle

def execute_slice():
  procedure_take()

def procedure_take():
  left_group, right_group = take_next_groups()
  procedure_join(left_group, right_group)

def procedure_join(left_group, right_group):
  for left_record in left_group:
    for right_record in right_group:
      result = left_record + right_record
      emit(result)
    if not right_group: # right_group is empty
      emit(left_record)
```

```python
# emit(join{left-outer}{L.x=R.x}(take())) -- by forward with broadcast

join_table = None

def setup_process():
  relation = get_broadcast()
  global join_table
  join_table = build_hash_table(relation)

def execute_slice():
  procedure_take()

def procedure_take():
  record = take_next_record()
  procedure_join(record)

def procedure_join(left):
  right = join_table.get(left.x)
  if right:
    left += right
  emit(record)
```

### プロセスの最適化

#### プロシージャのインライン展開

本項における「プロシージャ」の原理モデルでは、プロシージャの末尾で後続のプロシージャを呼び出すことで、プロセス全体の処理を表現していた。

```python
# offer(project{x=x+1}(filter{x<10}(take())))
def execute_slice():
  procedure_take()

def procedure_take():
  record = take_next_record()
  procedure_filter(record)

def procedure_filter(record):
  if record.x < 10:
    procedure_project(record)

def procedure_project(record):
  record.x = record.x + 1
  offer(record)
```

多くの場合、インライン展開することで、プロセス全体を平坦なプロシージャとして表現できる。

```python
# offer(project{x=x+1}(filter{x<10}(take())))
def execute_slice():
  record = take_next_record()
  if record.x < 10:
    record.x = record.x + 1
    offer(record)
```

特に、 `buffer` が出現しないプロセス演算グラフにおいては、その構造は必ずリストと同等のものになるため、インライン展開は比較的容易である。

逆に、 `buffer` が出現し、なおかつプロセス演算グラフがツリーとならない (下記「`confluent` 疑似演算子の導入」も参照のこと) 場合、必ずしも全体をインライン展開することが妥当であるかどうかは判断が難しい。

インライン展開することで、次のメリットが考えられる。

* コード生成時に最適化が効きやすくなる
  * 関数をまたぐ最適化 (Inter-Procedural Optimization: IPO) は比較的高コストであるため、
  * ただし、コード生成系が強制的にインライン展開を行う機能を有しているなら、そちらに任せるのもよさそう
* コピーの回数を削減できる
  * 関数呼び出しの際にレコードのコピーが発生しうるが、これを省略できる

#### 行データの独立化

前項の例では `record` といういわゆる構造体でデータを保持していたが、入力の各列を別個のローカル変数に格納することで、コード生成時のコンパイラの最適化を受けやすい。

```python
# offer{x}(project{a, x = a * 2, y = b * c}(take()))

def procedure_take():
  record = take_next_record()
  a = record.a
  b = record.b
  c = record.c

  # procedure_project
  x = a * 2
  y = b * c

  offer(x)
```

上記のような場合、最終的に使用されている変数は `x` のみであり、さらにその計算に必要な `a` のみである。
現代的なコンパイラには、上記に対して次のような最適化を行う。

```python
# offer{x}(project{a, x = a * 2, y = b * c}(take()))

def procedure_take():
  record = take_next_record()
  offer(record.a * 2)
```

このように、不可分な「行」というデータ構造ではなく、独立した変数とすることで、コード生成において以下の利点が得られる可能性がある。

* 使用されない列が存在する場合、一般的なコンパイラではその変数の代入すら行わない
* 実際に利用される変数であっても、途中から使われなくなるならば、その変数領域はほかの変数が再利用できる
* 演算子の内部で複雑な計算が行われていたとしても、プロセスが最終的に利用しなければ、その計算自体が省略されうる

#### `confluent` 疑似演算子の導入

原理モデルにおいては、リレー演算子はいずれも1入力を想定している。
本質的に2入力が必要な演算子についてはその直前で待ち合わせ (`shuffle` または `broadcast`) が必要であり、それらを利用することで実質的に1入力として取り扱っている。

`union{all}` という演算子について考えてみると、これは本質的に待ち合わせが不要でありながら、2入力を要する演算である。
現状ではリレー演算子のモデルの煩雑化を回避するため、 `forward` エクスチェンジによって代替することを想定している。
ただし、 `forward` エクスチェンジを経由することでいくらかの性能低下が予想されるため、プロセス演算グラフ内で本機能を実現する方法について検討する。

ここでは、本来の `union{all}` と区別するため、 `confluent` という疑似演算子を導入する。
この `confluent` について対応する「プロシージャ」を考えると、次のようになる。

```python
# R3(confluent(R1(...), R2(...)))

def procedure_R1(...):
  result = ...
  procedure_confluent(result)

def procedure_R2(...):
  result = ...
  procedure_confluent(result)

def procedure_confluent(record):
  procedure_R3(record);

def procedure_R3(record):
  ...
```

上記のように、 `confluent` に対応するプロシージャは、単に後続する演算子のプロシージャに処理を引き渡すだけのものとなる。
つまり、プロセス演算グラフのモデルや、前述のインライン展開が複雑になる点を除き、性能の面では `forward` エクスチェンジを利用するよりも有利である。

なお、現状では以下の理由で `confluent` を採用していない

* プロセス演算グラフのモデルを単純に保ちたい
* `union{all}` がそれほど出現しない
* `forward` が十分に高速

## スカラー式

スカラー式は、関係演算子の内部で個々のカラムを処理する際に出現する。

つまり、プロセスの内部にのみ出現する。

### スカラー式の基本的なデザイン

スカラー式は、本質的には「（現在の文脈の）行を受け取って、スカラー値を返す関数」である（以下、スカラー関数）。
これは、スカラー式の内部でカラムの参照が行われるため、参照先の行が必要となるためである。
なお、当参照の表現形式については、本文書では割愛する。

本書におけるプロセスのデザインでは、それぞれの関係演算子が「行やグループを処理するプロシージャ」としてすでに表現されている。
そのため、スカラー式を処理する際には、現在の行を対応するスカラー関数の引数にとって呼び出すだけで実現できる。

### スカラー式の実現例

```python
# filter{x > 0}(...)

def procedure_filter(record):
  condition = function_filter(record):
  if condition:
    procedure_next(record)

def function_filter(record):
  return record.x > 0
```

```python
# project{*, +y = 100, +z = x*2}(...)

def procedure_project(record):
  record.y = function_project_y(record)
  record.z = function_project_z(record)
  procedure_next(record)

def function_project_y(record):
  return 100

def function_project_z(record):
  return record.x * 2
```

### スカラー式の最適化

#### スカラー関数のインライン展開

プロセスにおけるインライン展開と同様の議論で、スカラー関数についてもインライン展開を行うことでいくつかのメリットを受けられる。

```python
# filter{x > 0}(...)

def procedure_filter(record):
  condition = function_filter(record):
  if condition:
    procedure_next(record)

def function_filter(record):
  return record.x > 0
```

上記の `function_filter` をインライン展開すると、以下のようなコードになる。

```python
# filter{x > 0}(...)

def procedure_filter(record):
  condition = record.x > 0:
  if condition:
    procedure_next(record)
```

上記をさらに、プロセスの最適化における「行データの独立化」と併用することで、コード生成系の恩恵を受けやすくなる。

なお、スカラー式では特にSQL特有の最適化（NULLに関する処理）を受けやすくなる。
対象のカラムがnull値でないことが制御構造から明らか（直前でnull検査を行っているなど）である場合、以降でそのカラムに対するnullの検査や、null検査の結果をもとにした分岐先の処理を丸ごと省略できる。

## 高度な話題

以下は、実行方式の原理モデルに含まれない技術について、アーキテクチャの方針に関するスケッチを紹介する。

### UDFの処理

UDFは次の方針で処理する。

* UDFの本体が単純なリレーション式や、スカラー式に還元できる場合、インライン展開を行い、ほかの要素と同様に取り扱う
* インライン展開が不可能な場合、論理IRとして表現されたプログラムとして保持しておき、実行時にインタープリタで解釈を行う

前者は物理実行計画上でUDFとして表出しないので特筆すべきことはない。
後者のステートメントインタープリタはおおよそ次のようなデザインである。

* 論理IR上の「ステートメント（文）」を1つずつ順番に解釈し、インタープリタの変数環境を更新していく
  * 解釈を行う際に、論理IRの文を物理IRのプログラムに変換し、それから実行してもよい
* 文がDMLでない場合、現在のスレッドで直接評価する
* 文がDMLである場合、ほかのDMLと同様にステップグラフを構築し、 **現在の** ステップグラフスケジューラ上で実行する
* 文にほかのUDFの呼び出しが含まれる場合、新しいインタープリタを用いて対象のUDFを再帰的に実行する

上記を実現するために、実行エンジンは以下の特性を有することが望ましい。

* DMLでない文を素早く実行するために、コード生成を行わなくてもスカラー演算相当が行える
  * 毎回コードを生成してもよいが、上記は1度しか実行しない
  * または、コンパイル済みバイナリをキャッシュし、同じ文のコンパイル結果を再利用できれば強い
* ステップグラフスケジューラが、リソースを共有して複数のDAGを実行できる
  * システム全体で単一のスケジューラを有するような設計であれば、リソースを有効に使えるうえ、トランザクション的にもかなり無茶なスケジューリングができる（ロックではなく、スケジュール側を調整するなど）

### 適応的コード生成

本文書で検討したモデルでは、プロセスをスライスに分解し、複数回実行することでプロセス全体を処理している。

このとき、プロセスの実行に必要なCPUは、おおよそ次のように計算できる（スライスのデータ偏りについては考慮しないものとする）。

```txt
プロセスの実行時間 = スライスの実行時間 x スライスの個数
```

ここで、スライスのコード生成を行うことを考えると、以下のようにあらわせる。

```txt
プロセスの実行時間 = コード生成時間 + コード実行時間 x スライスの個数
```

並列化を行っているために一概に言えないが、コード生成を行う上では以下のような式が成り立つことが望ましい。

```txt
コード生成時間 + コード実行時間 x スライスの個数 < スライスの実行時間 x スライスの個数
```

上記のモデルを単純化するため、コード生成によって、スライスの実行に要する時間は常に `1 / N` になると仮定する。
この場合、上式を次のように変形できる。

```txt
コード生成時間 + (1 / N) x スライスの実行時間 x スライスの個数 < スライスの実行時間 x スライスの個数

コード生成時間 < (N - 1) / N x スライスの実行時間 x スライスの個数
```

上記のうち、定数部分を無視すると、スライスの実行時間が十分に長いか、スライスの個数が十分に多い場合にコード生成するとよさそうである。
ただし、スライスの実行時間とコード生成の時間には一定の相関がありそうなので、特にスライスの個数に注目して議論を進める。

実行時にスライスの個数が確定するタイミングは、ほとんどの場合そのプロセスを実行する直前である。
さらに、 `forward` ではスライスの個数が確定する前に、部分的な実行が可能である。
そのプロセスを実行する直前に判断してコード生成を行うと、プロセスの待ち合わせ時間が延び、結果としてグラフ全体の所要時間が延びてしまうことになる。

それに対応するには、以下のような方法が考えられる。

a. プロセスを実行中に、次に実行可能になるプロセスを並行してコード生成する
b. プロセスの実行にコード生成が間に合わなければ、インタープリタを利用してコードを実行し、コード生成が完了したら次のスライスの実行から生成したコードを利用する

さらに踏み込んで、現代的なJITコンパイラのように、段階的に最適化コードを生成する手法も考えられる。

1. 最初はインタープリターで実行
1. 一定回数実行することがわかったら、弱い最適化でコード生成
1. さらに実行することがわかったら、やや強い最適化でプロファイリング用のコードを埋め込む
1. ホットスポットになることがわかったら、プロファイリング結果をもとに強い最適化でコードを生成

### リソーススケジューリング

ステップグラフを俯瞰してスケジューリングを行う機構を取り入れることで、ステップの実行に必要なCPUリソース（スレッド）の割り当てのみでなく、ステップが要求するメモリー使用量のコントロールを行うこともできる。

ステップグラフのモデルにおいて、特にメモリー使用量に影響する要素は以下である

1. エクスチェンジが蓄積するデータ
2. プロセスが `broadcast` から受け取って構築した表データ

前者のエクスチェンジのデータは、その上流のプロセス `P` からおおよその規模を推定できる

* `P` の入力エクスチェンジに蓄積されたデータ件数、または `scan` から取得する件数 (`N`)
* `P` の出力データの長さ (`V`)
* `P` の選択率 (`S`)

上記の変数群をもとに、 `N * S * V` がおおよその規模である。

同様に、後者の表データは、対応するエクスチェンジの容量に、一定の倍率をかけることでおおよその推定が可能である。

上記を前提として、メモリー使用量を制御するには、次のような手法が考えられる。

1. 不必要になったデータをメモリから除去する
2. しばらく使わないデータを補助記憶装置に退避する（スピルアウト）

前者のうち「不必要になったデータ」とは、以下があげられる。

1. 下流のプロセスがすべて完了しているエクスチェンジのデータ
1. 完了したプロセスから参照する表データ
1. すべての下流のプロセスが共通して読んだ部分のデータ

スケジューラは、上記を考慮して適切なプロセスを順番に実行、完了していくことで全体のメモリー使用量を抑制できる。
特に、 `forward` は後続のプロセスが即座に参照すれば、エクスチェンジ上に蓄積する必要がなくなる。

ただし、上記にも限界があるため、どうしようもない場合にはエクスチェンジの蓄積データをスピルアウトする手法が考えられる。
この場合、スケジューラの役割は、しばらく利用しないであろうエクスチェンジを選択し、スピルアウトの要求を行い、そのエクスチェンジを利用するプロセスの実行優先度を低下させることである。

ただし、エクスチェンジ上のインクリメンタル処理と、上記のスピルアウトは相性があまり良くない。
例えば、インクリメンタルに集約する手法では、スピルアウトした領域のデータを直接編集するのは高コストである。
また、インクリメンタル処理によって複雑なデータ構造を作成すると、直列化のコストも勘案する必要がある。

### 再帰問合せ

SQLの「再帰問合せ」は繰り返しの処理を含んでいるため、本書のステップグラフでは表現が難しい。
本稿では、ステップグラフを一部拡張することで、この再帰問合せを実現する方法を検討する。

再帰問合せを実現するにあたり、以下のような方針で変更を加えるものとする。

* ステップグラフに、再帰処理の範囲を表すためのエクスチェンジを新規に導入する
* ステップグラフでは明示的な循環を構成させない
* プロセス演算グラフは変更しない
* ステップスケジューラを拡張し、それぞれの完了したステップを完了していない状態に戻せるようにする

上記をもとに、再帰問合せの一般構造を下記に示す。

```txt
# wITH RECURSIVE U AS (
#   <Ginit>
#   UNION ALL
#   <Gtrans>
# )

 Ginit ----+  + . . . . +
  |        |  v         .
  |      exchange       .
  |  {recursive-begin}  .
  |         |           .
  | +---- Gtrans        .
  | |       |           .
  | |    exchange       .
  | | {recursive-end}   .
  | |       .           .
exchange    + . . . . . +
{forward}
  as U
```

上記のうち、末尾の `exchange{forward} as U` が再帰問合せの結果を表すリレーションとなる。
便宜上 `exchange{forward}` としているが、これは任意のエクスチェンジでよい。

上記のそれぞれの要素は以下の通りである。

`Ginit`
~ 非再帰項を表現するステップグラフの部分グラフ

`Gtrans`
~ 再帰項を表現するステップグラフの部分グラフ

  `exchange{recursive-begin}` に上流下達であり、かつ `exchange{recursive-end}` に下流可達なステップの集合からなる。

  `Gtrans` に含まれるすべてのプロセスの下流となるエクスチェンジのうち、 `Gtrans` に含まれず、かつ対応する `exchange{recursive-end}` でないもの（例では `exchange{forward} as U`）は、 `Gtrans` の反復が完了するまでエクスチェンジそのものを完了状態とすることはできない。

`exchange{recursive-begin}`
~ 再帰処理の開始を表すエクスチェンジ

  対応する `recursive-end` が一意に存在し、同一のデータ型を取り扱うものでなければならない。

`exchange{recursive-end}`
~ 再帰処理の終端を表すエクスチェンジ

  対応する `recursive-begin` が一意に存在し、同一のデータ型を取り扱うものでなければならない。

再帰問合せの一般的な構造は、 `Ginit` によって得られたリレーションに対し、合成された関係演算子 `Gtrans` を **推移的に適用** するものである。
つまり、 $R^*(U) = U \cup R(U) \cup R(R(U)) \cup R(R(R(U))) \cup ...$ となるような演算 $R^*$ を `Gtrans` でも実現できればよく、以下の処理と同等である。

```txt
Ginit -----+
 |         |
 |      forward
 |         |
 |+----- Gtrans
 ||        |
 ||     forward
 ||        |
 ||+---- Gtrans
 |||       |
 |||       .
 |||       .
 |||       .
 |||       |
 ||| +-- Gtrans
 |||~|
 ||| |
forward
   |
```

このような処理を実現するには、以下のような繰り返しを含む複雑な手順を行う。

1. `Ginit` を実行し、完了する
2. 以下を繰り返す
   1. `exchange{recursive-begin}` に蓄積データが存在しない場合、繰り返しを終了する
   2. `exchange{recursive-begin}` を完了させ、 `Gtrans` を再実行可能な状態にする
   3. `Gtrans` を実行し、完了する
      * このとき、 `Gtrans` に後続するエクスチェンジはまだ完了できない
   4. `exchange{recursive-begin}` を再実行可能な状態にし、 `exchange{recursive-end}` に蓄積されたデータを `exchange{recursive-begin}` へ移動させる
   5. 繰り返しの先頭へ
3. `exchange{recursive-begin}`, `Gtrans`, `exchange{recursive-end}` をそれぞれ完了状態にする

上記は原理モデルであり、高速化のためにいくつかの最適化が考えられる。

* ある反復で `recursive-end` に1つでも出力があれば再帰実行が成立するので、その時点でインクリメンタルに `recursive-begin` を再実行可能な状態にし、データを移動してよい
* さらに、 `recursive-begin` は下流から見れば `forward` 相当なので、 `recursive-begin` の完了を待たずに `Gtrans` の先頭を実行してもよい
* `Gtrans` の下流となる `recursive-end` 以外のエクスチェンジがこれ以上のデータを必要としなくなったら、その時点で繰り返しを終了させてよい

ただし、上記のいくつかの最適化を実現するにあたり、注意深くスケジューラを設計する必要がある。
現在の反復が完了する前に次回の反復を開始することになるため、異なる反復のデータが混ざってしまう可能性がある。
これを回避するには、スライスごとに現在の反復を記憶しておき、ステップの状態を反復ごとに異なるものとして取り扱えるようにしなければならない。

なお、再帰問合せを実現した場合、前述の「リソーススケジューリング」で行われる不要なデータの除去は、再実行されることを考慮しなければならなくなる。

### NUMA 環境の考慮

NUMA環境での並列化を考えた際に、いくつか思いついた点を挙げる。

* メモリアフィニティを確保するため、各スレッドは pinning する
* `forward` エクスチェンジによってデータ交換を行う際、前後のスライスは可能な限り同一スレッドで実行する
* `shuffle` エクスチェンジを実行する際に、アフィニティを意識してパーティションを構成する
  * パーティションはグループの集合で、同一パーティションのデータは可能な限り同一のメモリアフィニティを選択する
  * パーティションのデータをグループ化する際には、アフィニティをもとに実行するスレッドを選択する
  * パーティションを入力にとるスライスは、アフィニティをもとに実行するスレッドを選択する
* `broadcast` エクスチェンジのデータをもとに構成する表は、必要であればソケットごとにコピーを作成する
* ただし、上記はやりすぎるとスレッドの割り当てに偏りが生まれるため、良しあしではある

### マルチノード並列化

本文書ではこれまでにも並列化について取り使ってきたが、それらはいずれも同一のコンピュータ上であることを前提としてきた。
本稿では、複数のノードにまたがってステップグラフを実行する場合の、簡単なスケッチを行う。

まず、以下のような前提をおく。

* ノード数は `~20` 程度
* ノード間はRDMAによってデータ転送が可能
  * データ転送レイテンシは `100us` 程度
  * データ転送バンド幅は `20Gbps` 程度
* アプリケーションが異常終了した際に、途中から再開せず、最初からやり直してよい
* データベースへの操作は、特定のノード（コーディネーターノード）のみから行える
* コーディネーターノードのCPUやメモリーリソースは貴重であり、可能な限りその他のノード（ワーカーノード）上で行う

上記に対し、シングルノードのスケジューラに対して以下の方針で拡張を行う。

* プロセスや、それをもとにしたスライスの構造は、シングルノードのものと同様
* エクスチェンジは、それを入力データとして利用するノードに対し、データを転送する
  * 上記の想定では、スライスがエクスチェンジにデータの要求をした際に、初めてデータを転送する方式でよい (pull-style)
  * ただし、レイテンシを可能な限り隠すために、以下の方策をとる
    * スケジューラがプロセスにリモートスレッドを割り当てると同時に、対応するエクスチェンジの入力データも転送し始める
    * 入力データの転送はある程度のまとまりで行い、スケジューラもそのまとまりの単位でスライスを実行する
* `broadcast` エクスチェンジのデータをもとにプロセスの初期化を行う場合、ノードごとに初期化が必要になる
* `scan`, `insert`, `update`, `delete` などのコーディネータ上でしか動作しないプロセスは、必ずコーディネータ上で動作させる
* コーディネータ上で実行したプロセスの結果データは、可能な限りワーカースレッド上に退避させる

上記以外にも、 `VARCHAR` などのデータの持ち方を考慮したり、 `BLOB` などのアクセス方法を考慮したりする必要はありそう。

スケジューラ以外にも、コンパイラもある程度の拡張が必要になる。

* コーディネータ上で実行しなければならない作業を局所化し、 `forward` エクスチェンジを経由してワーカースレッドで動作可能なプロセスに分解する
* `scan` を複数回行うような場合、一度だけ `scan` してそのデータをグラフ内で再利用することも検討する
  * ただし、それによってリードセットが膨大になったり、メモリが足らなくなる可能性もあるため、一概には言えない

本環境での高速化は、前述の「NUMA環境の考慮」と類似の手法が利用できる。

### ベクトル化演算

並列化とは異なる観点で、ベクトル化演算の利用について検討する。

ここまでのモデルでは、プロセス演算グラフは「行（または同値グループ）を処理するプロシージャ」として抽象化を行ってきた。
対して、ベクトル化演算を行うには、行ではなく「列ベクトルの組」に対して処理を行う必要がある。

上記に対し、ベクトル化演算のために以下のような拡張を行う。

* プロセス
  * 主入力エクスチェンジから取得できるデータ形式を「行」や「同値グループ」から「列ベクトルの組」に変更する
  * プロシージャの入力単位を「行」や「同値グループ」から「列ベクトルの組」に、出力も「列ベクトルの組」に変更する
  * 出力エクスチェンジへの出力形式を「行」から「列ベクトルの組」に変更する
  * `filter` などの行を減らすタイプの演算では、行の存在を 1-bit で表す列を追加し、実際に行を削らない
    * `offer` 時にまとめて処理するなど
* エクスチェンジ
  * 蓄積するデータのレイアウトを、「行のベクトル」から「列ベクトルの組」に変更する
  * ベクトル化演算を適用しやすいようデータを分割し、メモリアライメントを調整する

上記のうち「列ベクトルの組」は、必ずしもリレーション全体を表す必要はなく、ハードウェアが提供するベクトル化演算の単位に区切ったものでよい。

また、必ずしもすべての関係演算子について上記の変換を行う必要はなく、必要に応じてごく一部の箇所だけ適用するのもよい。
たとえば、トランザクションエンジンが有するデータ構造がベクトル化されていない場合、 `scan` の結果をベクトル化するには「行のベクトル」から「列ベクトルの組」に変換する分のコストがかかる。

また、プロセス内に演算スタイルが異なるプロシージャ混在してしまうと、データ構造の組み換えが多発してしまうため、変更する単位には注意が必要である。

### トランザクションヒンティング

本項では、トランザクションエンジンに対するスケジュール上のヒントを与える方法について議論する。

たとえば、以下のようなDMLについて考える。

```sql
UPDATE T1
SET v = T1.v + 1
WHERE T1.id IN ('x', 'y', 'z')
AND some_complex_predicate(T1.v)
```

上記のうち、 `T1.id` の文字列に対応するページ `x`, `y`, `z` をそれぞれ `read` し、そのうち `x`, `z` についてのみ更新するとした場合、例えば `r(x) w(x) r(y) r(z) w(z)` のような操作順序になる。

しかし、本書における実行モデルを利用した場合、トランザクション内における `read`, `write` の操作は一定の規則の下で順序が入れ替わる。
おそらく、 `r(x) r(y) r(z) w(x) w(z)` のようにいくつかの単位でまとめて読み出した後に、まとめて書き込む、という操作順序になることが予想される。
これに含まれる、 `r(x)-w(x)` はいわゆる read-modify-write の組になるが、実際には `r(x)` から `w(x)` まで時間が空いてしまい、それによってほかのトランザクションの `w(x)` が割り込みやすくなってしまう懸念がある。

これらのスケジューリングを改善するため、以下の3種類のヒント機構を導入する。

1. attributed read
2. attributed write
3. attributed operation

#### attributed read

attributed read は `scan` 系の演算子に以下の指示を追加することで、 `read` オペレーションが発生する際に適切なヒントを与えるためのものである。

`read-only`
~ 本属性を付与した `scan` の結果得られたページは、以降の `write` にいかなる影響も与えない。

  これは、DMLにおける `SELECT` のうち、以降でその結果がデータベースに書き戻されることがない場合を想定している。

`possibly-write{P}`
~ 本属性を付与した `scan` の結果得られたページを利用し、ページ集合 `P` の `write` を行う可能性がある。

  なお、 `P` は実際に発生した `read` オペレーションの対象のページから計算される。

  ただし、この属性が付与されていなくても、対象のページやその他のページに書き出す可能性はある。
  あくまで、その可能性があることを明示的に示唆しているのみ。

  基本的に、 `INSERT` などで書き出す先のページを推定する場合のみ使う。

`only-write{P}`
~ 本属性を付与した `scan` の結果得られたページを利用し、ページ集合 `P` の `write` を行う可能性があり、かつページ集合 `P` 以外への `write` にいかなる影響も与えない。

  なお、 `P` は実際に発生した `read` オペレーションの対象のページから計算される。

  ただし、実際には `write` を行わない可能性もある。

  これは、DMLにおける `UPDATE`, `DELETE` を想定している。

  なお、 `read-only` は $P = \emptyset$ と等価である。

性能上の問題で、上記のうち `P` は「読みだしたページ自身」に制限する可能性がある。
この場合、ヒントが実際にトランザクションエンジンに通知されるのは、 `read` オペレーションと同時である。

そうだとしても、先ほどの例は次のようになる。

```sql
UPDATE T1
SET v = T1.v + 1
WHERE T1.id IN ('x', 'y', 'z')
AND some_complex_predicate(T1.v)

-- > `r(x)[only-write{x}] r(y)[only-write{y}] r(z)[only-write{z}] w(x) w(z)`
```

#### attributed write

attributed write は `insert`, `update`, `delete` 系の演算子に以下の指示を追加することで、 `write` オペレーションが発生する際に適切なヒントを与えるためのものである。

`blind`
~ 本属性を付与した演算による `write` は、いかなる `read` も前提としていないことを表す。

  たとえば、以下のようなDML2文からなるトランザクションについて考える。

  ```sql
  SELECT COUNT(*) FROM ITEMS;
  INSERT INTO AUDIT_TABLE VALUES ( 'nautilus', NOW() );
  ```

  上記は `SELECT`, `INSERT` を順に行っているが、これらは文の実行順序に本質的に依存しない。

`only-cause{P}`
~ 本属性を付与した演算による `write` は、ページ集合 `P` に対する `read` のみを前提としている。

  なお、 `P` は実際に発生した `write` オペレーションの対象のページから計算される。

  ただし、 `P` には実際には無関係のページも含まれている可能性がある。

性能上の問題で、上記のうち `P` は「書き込んだページ自身」に制限する可能性がある。
この場合、ヒントが実際にトランザクションエンジンに通知されるのは、 `write` オペレーションと同時である。

そうだとしても、先ほどの例は次のようになる。

```sql
UPDATE T1
SET v = T1.v + 1
WHERE T1.id IN ('x', 'y', 'z')
AND some_complex_predicate(T1.v)

-- > `r(x) r(y) r(z) w(x)[only-cause{x}] w(z)[only-cause{z}]`
```

TBD: 全体的に要らないかも？

#### attributed operation

attributed operation は、上記 attributed read/write 以外のあらゆる演算子に指示を追加したもので、 `read`, `write` とは独立したヒントを適宜トランザクションエンジンに与えるためのものである。

基本的には、実際に `read` した情報をもとに、実際の `write` をどのように行うか、という情報を提供する。

`R[write]`
~ 任意の演算子 `R` を通過した行の元になったページは、必ず `write` の対象となる

`filter[write-only-if]`
~ この選択演算子を **通過しなかった** 行の元になったページは、必ず `write` の対象と **ならない**

現状は0階の様相のみを考え、かつ最大限有用なものだけを記載した。
つまり、上記で得られる情報は、「具体的な `write` オペレーションの予告」のみである。

先ほどの例は次のようになる。

```sql
UPDATE T1
SET v = T1.v + 1
WHERE T1.id IN ('x', 'y', 'z')
AND some_complex_predicate(T1.v)

-- > `r(x) [always w(x)] r(y) [never w(y)] r(z) [always w(x)] w(x) w(z)`
```

なお、やろうと思えば `R[(possibility)-write{P}]` のように、ページ集合を自由に定めつつ、さらに possibility を指定するようなことも可能。

#### トランザクションヒンティングに関する議論

以下では、本実行モデルにおける **実行時におけるヒントの具体的な語彙** について、これまでのモデルをもとに案を検討する。

まず、本実行モデルはトランザクションエンジンの情報をもとに、 `read`, `write` オペレーション自体の順序を変更することを想定していない。
そのため、ヒントとして有用になりうるのは、以下のいずれかであると考える:

* `read` オペレーションが、対象ページの適切なバージョンを選択する上で有用な情報
* `write` オペレーションが、トランザクションオーダーに制限を課すうえで有用な情報

また、実行時に提供するヒントであるため、以下のようなコンセプトで設計するのがよさそうである。

* `read`, `write` と同時、またはそれらに先行してそれぞれのオペレーションの特性の情報を得られること
  * インクリメンタルにスケジューリングを行うため、オペレーション以降に追加情報が来ても遅い可能性が高い
* 具体的な個々のページに関して言及すること
  * あまり複雑すると、逆に性能の問題が起こる

上記を考慮し、今回は以下の3パターンに分類してヒントを差し込めるように設計した。

1. `read` オペレーションと同時 (attributed read)
   * 対象の `read` が `read-modify-write` となる確度
   * 対象の `read` が `read-only` であるかどうか
2. `write` オペレーション以前 (attributed operation)
   * 任意の `write` の確度
     * 現状では `always`, `never`
     * 追加するとしたら `likely`, `unlikely`
3. `write` オペレーションと同時 (attributed write)
   * 対象の `write` が `blind` であるかどうか
   * 対象の `write` が構成する read-from 関係の自由度
     * `write` が直接依存する `read` を絞ってもスケジュールに影響しない場合、この情報は不要そうである

上記のうち、 個々の `write` オペレーションに対し、 read-from 関係にある `read` を減らすことにどれだけ意義があるかは微妙である。
なぜなら、トランザクションオーダーを決めるうえでは、トランザクションに含まれる `write` 全体について、 read-from 関係の有無を調べるため、個々の `write` に関連する `read` はスケジュールに寄与しない可能性がある。
対して、個々の `read` オペレーションが `read-only` であるかどうかは、 `write` 全体の read-from 関係に影響するため、逆にそちらだけでよいのではないかと考えている。

これらを整理すると、トランザクションエンジンは実行時用のヒントのため、以下のような機能を有するのが良いのではないかと考える。

* `read` の付帯属性
  * `read` と同時に、対象のページに対して `write` が将来発生する確度を指示する
    * `never` は前項の `read-only` と等価とする
* `write` の付帯属性
  * `write` と同時に、そのオペレーションが `blind` かどうかを指示する (TBD: いる？)
* `write` の予告
  * 任意のタイミングで、特定のページに対して `write` が将来発生する確度を指示する

上記のうち、「確度」については以下の種類とする。

* `always` - 確実に事象が発生する
* `likely` - 比較的高確率で事象が発生する
* `possibly` - 事象が発生しうる (情報がない場合の規定の確度)
* `never` - 確実に事象が発生しない

## TBD

* `shuffle` base join を行う際、現状のモデルではプロセスに対して2個の `shuffle` が必要になる。これを単一の `shuffle` にまとめることでエクスチェンジのインクリメンタル実行の範囲が広がり、 `take` 疑似演算子のメンタルモデルが素直になる。が、逆にエクスチェンジの処理内容は複雑になる
* `scan{DUAL}` 相当の疑似演算子
  * -> `constant{'X'}` ?
